{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cb05b825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.datasets import fetch_lfw_people"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4f6370",
   "metadata": {},
   "source": [
    "## create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9a2df71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = \"./lfw\"\n",
    "\n",
    "destination_dir = \"./Other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4c8c7d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d4de92f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images copied successfully!\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(destination_dir, exist_ok=True)\n",
    "\n",
    "count = 0\n",
    "# Iterate through the folders in the source directory\n",
    "for folder_name in os.listdir(source_dir):\n",
    "    folder_path = os.path.join(source_dir, folder_name)\n",
    "\n",
    "    # Skip any non-directory items\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "    \n",
    "    # Iterate through the image files in each folder\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        # Skip any non-image files\n",
    "        if not file_name.lower().endswith(('.jpg', '.jpeg', '.png', '.gif')):\n",
    "            continue\n",
    "\n",
    "            \n",
    "        image = cv2.imread(file_path)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        faces = faceCascade.detectMultiScale(gray,scaleFactor=1.1, minNeighbors=10, minSize=(40, 40))\n",
    "    \n",
    "        if len(faces) > 0:\n",
    "        \n",
    "          for i, (x,y,w,h) in enumerate(faces):\n",
    "      \n",
    "              # To draw a rectangle in a face\n",
    "             face = image[y:y+h, x:x+w]\n",
    "             image_file = os.path.join(destination_dir, f\"image_{count}.jpg\")\n",
    "             cv2.imwrite(image_file, face)\n",
    "        count+=1\n",
    "        break\n",
    "    if count > 700:\n",
    "        break\n",
    "print(\"Images copied successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5137b93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "source_dir = glob.glob(\"./My/*\")\n",
    "\n",
    "destination_dir = \"./Zahra\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d25447ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face images saved successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid SOS parameters for sequential JPEG\n"
     ]
    }
   ],
   "source": [
    "count = 0 \n",
    "os.makedirs(destination_dir, exist_ok=True)\n",
    "for file_name in source_dir:\n",
    "    if not file_name.lower().endswith(('.jpg', '.jpeg', '.png', '.gif')):\n",
    "            continue\n",
    "    image = cv2.imread(file_name)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = faceCascade.detectMultiScale(gray,scaleFactor=1.1, minNeighbors=10, minSize=(40, 40))\n",
    "    \n",
    "    if len(faces) > 0:\n",
    "        \n",
    "       for i, (x,y,w,h) in enumerate(faces):\n",
    "      \n",
    "        # To draw a rectangle in a face\n",
    "        face = image[y:y+h, x:x+w]\n",
    "        image_file = os.path.join(destination_dir, f\"image_{count}.jpg\")\n",
    "        cv2.imwrite(image_file, face)\n",
    "\n",
    "        count += 1\n",
    "print(\"Face images saved successfully!\")         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "db690fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "my_images = glob.glob(\"./Zahra/*\")\n",
    "other_images = glob.glob(\"./Other/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "54a14daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "28a51f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy\n",
    "\n",
    "def preprocess_img(filepath):\n",
    "    \n",
    "  try:\n",
    "    img = cv2.imread(filepath)\n",
    "    \n",
    "    img = cv2.resize(img,target_size)\n",
    "\n",
    "    img_array = np.array(img).flatten()\n",
    "    #img_array = np.array(img)\n",
    "    \n",
    "    #img_array = img_array / 255.0\n",
    "  \n",
    "    return img_array\n",
    "\n",
    "  except Exception as e:\n",
    "                print(f\"Error processing image {filepath}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "16e5a299",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "92397f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in my_images:\n",
    "    \n",
    "    img_array = preprocess_img(path)\n",
    "    label = 1\n",
    "    \n",
    "    images.append(img_array)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "58e966ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in other_images:\n",
    "    \n",
    "    img_array = preprocess_img(path)\n",
    "    label = 0\n",
    "    \n",
    "    images.append(img_array)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4535fb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(images, dtype=np.uint8)\n",
    "labels = np.array(labels, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "73b49d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1092"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c68cac4",
   "metadata": {},
   "source": [
    "## Split the data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "37b51775",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(images, labels, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0bfd4a",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb013fae",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "94d9bdc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train = train_images\n",
    "X_test = test_images\n",
    "\n",
    "X_train_reshape = train_images.reshape(train_images.shape[0], -1)\n",
    "X_test_reshape = test_images.reshape(test_images.shape[0], -1)\n",
    "\n",
    "\n",
    "# Create a Random Forest classifier with 100 trees\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train_reshape, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "00dd4e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred = rf.predict(X_test_reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "3113dd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9726027397260274\n",
      "Precision: 1.0\n",
      "Recall: 0.9310344827586207\n",
      "F1 score: 0.9642857142857143\n",
      "confusion_matrix:\n",
      " [[132   0]\n",
      " [  6  81]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(test_labels, rf_pred)\n",
    "precision = precision_score(test_labels, rf_pred)\n",
    "recall = recall_score(test_labels, rf_pred)\n",
    "f1_score = f1_score(test_labels, rf_pred)\n",
    "conf_mat = confusion_matrix(test_labels, rf_pred)\n",
    "\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 score: {f1_score}\")\n",
    "print(f\"confusion_matrix:\\n {conf_mat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d00302",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "65eabbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(C=10, kernel='poly', gamma='auto')\n",
    "\n",
    "svm.fit(X_train_reshape, train_labels)\n",
    "\n",
    "\n",
    "svm_pred = svm.predict(X_test_reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5732bfb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9497716894977168\n",
      "confusion_matrix:\n",
      " [[125   7]\n",
      " [  4  83]]\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(test_labels, svm_pred)\n",
    "conf_mat = confusion_matrix(test_labels, svm_pred)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"confusion_matrix:\\n {conf_mat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce94e10d",
   "metadata": {},
   "source": [
    "LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3d1e21de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asus/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "logreg.fit(X_train_reshape, train_labels)\n",
    "logreg_pred = logreg.predict(X_test_reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f2c90cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9726027397260274\n",
      "Precision: 0.9550561797752809\n",
      "Recall: 0.9770114942528736\n",
      "F1 score: 0.9659090909090908\n",
      "confusion_matrix:\n",
      " [[128   4]\n",
      " [  2  85]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(test_labels, logreg_pred)\n",
    "precision = precision_score(test_labels, logreg_pred)\n",
    "recall = recall_score(test_labels, logreg_pred)\n",
    "f1_score = f1_score(test_labels, logreg_pred)\n",
    "conf_mat = confusion_matrix(test_labels, logreg_pred)\n",
    "\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 score: {f1_score}\")\n",
    "print(f\"confusion_matrix:\\n {conf_mat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b7377aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs = logreg.predict_proba(X_test_reshape)[:, 1]\n",
    "\n",
    "best_accuracy = 0\n",
    "best_threshold = 0\n",
    "for threshold in np.linspace(0, 1, 101):\n",
    "    predicted_labels = (test_probs >= threshold).astype(int)\n",
    "    accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_threshold = threshold\n",
    "\n",
    "predicted_labels = (test_probs >= best_threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c15aec71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.2\n",
      "Accuracy: 0.9726027397260274\n",
      "Precision: 0.9550561797752809\n",
      "Recall: 0.9770114942528736\n",
      "confusion_matrix:\n",
      " [[128   4]\n",
      " [  2  85]]\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "test_precision = precision_score(test_labels, predicted_labels)\n",
    "test_recall = recall_score(test_labels, predicted_labels)\n",
    "test_conf_mat = confusion_matrix(test_labels, predicted_labels)\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Best threshold:\", best_threshold)\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"Precision: {test_precision}\")\n",
    "print(f\"Recall: {test_recall}\")\n",
    "print(f\"confusion_matrix:\\n {test_conf_mat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "925e032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"model-face.pkl\", \"wb\") as f:\n",
    "    pickle.dump(rf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "250c9595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"model-face.pkl\", 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8277c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring XDG_SESSION_TYPE=wayland on Gnome. Use QT_QPA_PLATFORM=wayland to run on Wayland anyway.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Define the number of forms to start before face recognition is enabled\n",
    "forms_started = 1\n",
    "max_forms = 20\n",
    "\n",
    "frames = []\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "who = None\n",
    "who_faces = None\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "       ret, frame = cap.read()\n",
    "       if not ret:\n",
    "           break\n",
    "\n",
    "            \n",
    "       gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "       faces = face_cascade.detectMultiScale(gray,scaleFactor=1.1, minNeighbors=10, minSize=(40, 40))\n",
    "    \n",
    "       if len(faces) > 0:\n",
    "        \n",
    "         for i, (x,y,w,h) in enumerate(faces):\n",
    "      \n",
    "            # To draw a rectangle in a face\n",
    "            face = frame[y:y+h, x:x+w]\n",
    "            frames.append(face)\n",
    "            \n",
    "       if forms_started >= max_forms:\n",
    "          who = frame\n",
    "          who_faces = faces\n",
    "          break\n",
    "            \n",
    "       forms_started+=1\n",
    "     \n",
    "except:\n",
    "    print(f'Video has ended..')  \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Define the number of consecutive face recognitions required for entry\n",
    "required_recognitions = 5\n",
    "consecutive_recognitions = 0\n",
    "\n",
    "\n",
    "total = 0\n",
    "for img in frames:\n",
    "\n",
    "    img = cv2.resize(img,(128, 128))\n",
    "    img_array = np.array(img).flatten()\n",
    "\n",
    "\n",
    "    predict =  model.predict(img_array.reshape(1, -1))\n",
    "    total+=1\n",
    "    if predict ==1 :\n",
    "        consecutive_recognitions +=1\n",
    "        0\n",
    "if consecutive_recognitions > required_recognitions : \n",
    "    color = (0, 255, 0)  \n",
    "    prob = (consecutive_recognitions / total)*100\n",
    "    label = f'Hello Zahra    {prob}%'\n",
    "else:\n",
    "    color = (0, 0, 255)  \n",
    "    prob = (1- (consecutive_recognitions / total))*100\n",
    "    label = f'can not login       {prob}%'\n",
    "\n",
    "\n",
    "if len(who_faces) > 0:\n",
    "   for i, (x,y,w,h) in enumerate(faces):\n",
    "      \n",
    "      # To draw a rectangle in a face\n",
    "      cv2.rectangle(who,(x,y),(x+w,y+h),color,2)\n",
    "      cv2.putText(who, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "\n",
    "   cv2.imshow(\"image\",who)\n",
    "   cv2.waitKey(0)\n",
    "   cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd7b1a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
